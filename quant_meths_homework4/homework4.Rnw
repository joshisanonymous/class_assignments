\documentclass{article}
  % Packages and package settings
  \usepackage{fontspec}
    \setmainfont{Charis SIL}
  \usepackage{hyperref}
    \hypersetup{colorlinks=true,
                allcolors=blue}
  \usepackage{natbib}
    \bibliographystyle{apalike}
  % Title info
  \author{Joshua McNeill}
  \title{Homework 4}
  \date{\today}
\begin{document}
  \maketitle
  <<settings_load_script, echo = FALSE>>=
  read_chunk("homework4.R")
  opts_chunk$set(echo = FALSE,
                 warning = FALSE,
                 message = FALSE,
                 fig.height = 4,
                 fig.width = 4,
                 results = "asis")
  @
  <<load_libraries_data>>=
  @
  \citet{lynott_modality_2009} collected experimental data on an ordinal scale from 0 to 5 to determine which of five senses subjects felt they experienced different adjectives through. Attempting to correlate these ratings with word frequencies, researchers constructed a multiple regression model with word frequency in the BNC as the response variable and the means of the ratings for each sense as the explanatory variables. The results are summarized in Table \ref{tab:linear_model_summary} and suggest that only the mean visual ratings predict word frequency in that words with higher visual ratings are more frequent. An ANOVA was also performed with word frequency as the response variable and words classified by which sense received the highest mean rating, which produced an $F$ of \Sexpr{round(senses.anova.summary$fstatistic, 3)} with $df$s of \Sexpr{senses.anova.summary$fstatistic[2]} and \Sexpr{senses.anova.summary$fstatistic[3]} where $P<$ 0.001. The distributions can be seen in the box plot in Figure \ref{fig:bnc_freq_boxplots}. However, it is necessary to check all the assumptions for using both a multiple regression model or an ANOVA in order to know whether these results are reliable.
  
  \begin{table}
    \centering
    \caption{Summary of a multiple regression model with BNC word frequency as the response and mean sense ratings for words as the explanatory variables.}
    \label{tab:linear_model_summary}
    <<linear_model_summary>>=
    @
  \end{table}
  
  \begin{figure}
    \centering
    \caption{Box plots for word frequency by their dominant sense ratings.}
    \label{fig:bnc_freq_boxplots}
    <<bnc_freq_boxplots, fig.height = 4>>=
    @
  \end{figure}
  
  \section{Multiple regression model assumptions}
    There are several assumptions that need to be checked when using mutliple regression models. First is whether the observations are independent. As there is no reason to believe that they are not, this assumption is passed. Second is that the response variable, the log of BNC word frequency, should be at least interval-scaled. The log of BNC word frequency is in fact ratio-scaled as a count of 0 is meaningful and a count of less than 0 is absurd. intervals between each value are also regular.
    
    \begin{figure}
      \centering
      \caption{Component-residual plot for mean visual ratings.}
      \label{fig:bnc_freq_visual_crplot}
      <<bnc_freq_visual_crplot, fig.height = 4>>=
      @
    \end{figure}
    
    A third assumption, that the relationship between response and explanatory variables is linear, takes a bit more analysis to pass. As only the visual rating was shown to be statistically significant, its linearity in relation to word frequency is most important to check, which can be done with with a component-residual plot as in Figure \ref{fig:bnc_freq_visual_crplot}. The wavy line about the straight dashed line in the plot suggests that this relationship is not quite linear.
    
    It is also not entirely clear if the fourth assumption is met when looking at the plot, which is that the errors must have a constant variance (i.e., they must be homoscedastic). For this, a non-constant variance score test can be performed where the null hypothesis is that the variance is constant. This returns a $\chi^2$ of \Sexpr{round(senses.lm.ncv$ChiSquare, 3)} with a $df$ of \Sexpr{senses.lm.ncv$Df} where $P<$ \Sexpr{round_any(senses.lm.ncv$p, 0.001, ceiling)}. The null hypothesis is thus rejected, meaning that the errors are not in fact homoscedastic. This is also the case when specifying for the mean visual rating only, as well, which yields a $\chi^2$ of \Sexpr{round(senses.lm.ncv.visual$ChiSquare, 3)} with a $df$ of \Sexpr{senses.lm.ncv.visual$Df} where $P<$ \Sexpr{round_any(senses.lm.ncv.visual$p, 0.001, ceiling)}. This makes two assumptions for using a multiple regression model that have not been passed.
    
    \begin{table}
      \centering
      \caption{VIF scores for the multiple regression model.}
      \label{tab:linear_model_vif_scores}
      <<linear_model_vif_scores>>=
      @
    \end{table}
    
    The fifth assumption that must be checked is that there must not be any multicollinearity between explanatory variables. Table \ref{tab:linear_model_vif_scores} shows the variance inflation factors (VIF) for the explanatory variables in question. As they are all under 5, this assumption is passed.
    
    The sixth assumption is that the residuals are not autocorrelated. This can be checked using the Durbin-Waston test. The null hypothesis for this test is that the residuals are not autocorrelated. In this case, the test returns a $D$-$W$ of \Sexpr{round(senses.lm.dw$dw, 3)} where $P>$ \Sexpr{round_any(senses.lm.dw$p, 0.001, floor)}.
    
    \begin{figure}
      \centering
      \caption{Q-Q plot for the multiple regression model.}
      \label{fig:bnc_freq_qqplot}
      <<bnc_freq_qqplot>>=
      @
    \end{figure}
    
    Finally, the seventh assumption to check is that the residuals are normally distributed. Visually, this can be checked with a Q-Q plot, as in Figure \ref{fig:bnc_freq_qqplot}. The lack of linearity suggests that the residuals are not normally distributed, but this can be further checked with a Shapiro-Wilk test for normality, which returns a $W$ of \Sexpr{round(senses.lm.sw$statistic, 3)} where $P<$ \Sexpr{round_any(senses.lm.sw$p.value, 0.001, ceiling)}. The null hypothesis of this test that the residuals are normally distributed is thus rejected, meaning that this assumption has not been passed.
    
  \section{ANOVA assumptions}
    There are fewer assumptions to check for performing an ANOVA, but they are still necessary. The first two are the same as those that were already checked and passed for the multiple regression model: that the observations are independent and that the response variable is at least interval-scaled.
    
    \begin{table}
      \centering
      \caption{Shapiro-Wilk test for normality}
      \label{tab:anova_normality}
      <<anova_normality>>=
      @
    \end{table}
    
    It is also important to make sure that the population that the sample was drawn from is normally distributed or that the sample sizes, in this case the groups, are the same. The sample sizes are clearly different, ranging from \Sexpr{min(table(adj$DominantModality))} to \Sexpr{max(table(adj$DominantModality))}. Performing a Shapiro-Wilk test for normality then on each sample yields the results in Table \ref{tab:anova_normality}. The null hypothesis can be rejected for each sample, meaning that none of them are normally distributed.
    
    Finally, the populations from which the samples come should have equal variances (i.e., they should be homoscedastic). For this, Levene's test for homogeneity of variance can be performed in which the null hypothesis is that the variances are in fact equal. In this case, the test returns an $F$ of \Sexpr{round(senses.anova.lev$'F value'[1], 3)} with $df$s of \Sexpr{senses.anova.lev$Df[1]} and \Sexpr{senses.anova.lev$Df[2]} where $P<$ \Sexpr{round_any(senses.anova.lev$'Pr(>F)'[1], 0.001, ceiling)}. The null hypothesis is therefore rejected, meaning the variances are not equal. As both the homoscedacity and normality assumptions have not been passed, the one-way ANOVA used by the researchers is not reliable.
  \section{Non-parametric tests}
    \begin{table}
      \centering
      \caption{Comparison of multiple regression model estimates to bootstrapped 95\% confidence intervals.}
      \label{tab:comparison_lm_boot}
      \begin{tabular}{l | r | r}
        Term & LM Estimate & Bootstrapped CI\\
        \hline
        (Intercept) & \Sexpr{round(senses.lm$coefficients[1], 3)} & \Sexpr{round(senses.boot.ci1$bca[4], 3)} to \Sexpr{round(senses.boot.ci1$bca[5], 3)} \\
        Visual & \Sexpr{round(senses.lm$coefficients[2], 3)} & \Sexpr{round(senses.boot.ci2$bca[4], 3)} to \Sexpr{round(senses.boot.ci2$bca[5], 3)} \\
        Haptic & \Sexpr{round(senses.lm$coefficients[3], 3)} & \Sexpr{round(senses.boot.ci3$bca[4], 3)} to \Sexpr{round(senses.boot.ci3$bca[5], 3)} \\
        Auditory & \Sexpr{round(senses.lm$coefficients[4], 3)} & \Sexpr{round(senses.boot.ci4$bca[4], 3)} to \Sexpr{round(senses.boot.ci4$bca[5], 3)} \\
        Olfactory & \Sexpr{round(senses.lm$coefficients[5], 3)} & \Sexpr{round(senses.boot.ci5$bca[4], 3)} to \Sexpr{round(senses.boot.ci5$bca[5], 3)} \\
        Gustatory & \Sexpr{round(senses.lm$coefficients[6], 3)} & \Sexpr{round(senses.boot.ci6$bca[4], 3)} to \Sexpr{round(senses.boot.ci6$bca[5], 3)} \\
      \end{tabular}
    \end{table}
    Since the parametric tests were not appropriate, non-parametric tests can be used. In the case of the regression analysis, this means bootstrapping to see if the estimates from the original multiple regression model fall within the bootstrapped confidence intervals. Table \ref{tab:comparison_lm_boot} shows how this comparison breaks down for each explanatory variable. As it happens, the estimates all fit within the bootstrapped confidence intervals with the exception of the olfactory variable, suggesting that the results from the original multiple regression model were in fact accurate and that mean visual ratings for words are correlated with word frequency in the BNC.
    
    As for the ANOVA, the non-parametric approximative K-sample permutation test can be used since many of the assumptions were not passed. This test yields a $\chi^2$ of 67.691 where $P<$ 0.001. One can conclude then that the dominance of one sense or another for an adjective is linked to its frequency in the BNC in some way, just as the researchers' parametric ANOVA suggested.
  \bibliography{References}
\end{document}